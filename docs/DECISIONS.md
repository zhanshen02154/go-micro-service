# 决策记录

## ADR-011: 撤销[ADR-008-服务注册/发现及配置从Consul迁移至ETCD](https://github.com/zhanshen02154/go-micro-service/blob/master/docs/DECISIONS.md#adr-008-服务注册/发现及配置从Consul迁移至ETCD)
### 日期
2025年12月19日
### 状态
已采纳
### 背景
原计划迁移Consul到ETCD，但Apisix官方无支持ETCD服务发现的组件。
### 最终方案
- 撤销ADR-008。
- 优化ETCD分布式锁实现共享会话，降低网络资源开销。
### 采纳理由
- 配置仍可迁移到ETCD，后续规划将其迁移，同时保证两个ETCD客户端不会冲突。
- 4.0--6.0的规划主要以完善系统的可观测性为主。
- 在4.0迭代过程中做了技术选型变更，并补充了SQL日志，开发时间长于预期，故选择优先搭建日志系统。
- 自行编写组件可能带来更多不可控的风险，故保留Consul作为服务发现和配置存储组件。

---

## ADR-010: 日志收集方案
### 日期
2025年12月18日
### 状态
已采纳
### 背景
1.0-3.0版几乎为黑盒难以排查只能通过htop结合阿里云ECS的监控来观测，需要完善日志以增强可观测性。日志来源如下：
- 框架组件
- GRPC请求
- 发布事件
- 订阅事件
- SQL
- Apisix

采集来源众多格式不统一，还要避免影响整体性能。
### 方案A
利用面向接口编程封装日志记录器并挂载到Wrapper，再用Broker推送到Kafka，同时将broker的生产端改为AsyncProducer，由fluent bit从kafka拉取日志写入到ES。
#### 优点
- 统一输入来源，利用kafka高吞吐的特性结合AsyncProducer异步推送。
- 无需引入第三方组件即可实现。
#### 缺点
- 框架的logger改动空间有限，多种来源混合不易判断。
- broker的生产端是全局更改，更换成异步推送后无法再使用同步生产端。
- 异步发布消息逻辑复杂，需同步改动发布事件方案。
### 方案B
用zap将日志输出到stdout，让fluent bit采集日志并写入到ES。
#### 优点
- 将日志收集和服务分离，服务端只需输出日志，其余交给fluent bit处理
- 安装ETCD客户端组件时已带有zap组件，引入zap实为充分利用已安装的依赖。
#### 缺点
- 框架的logger仍无法被最大化利用。
### 最终方案
结合A和B制定的折中方案：
- 服务日志：框架的logger配合zap记录框架产生的日志，GRPC请求、发布事件、订阅事件及SQL日志直接操作zap，fluent bit负责收集和写入日志到ES。
- Apisix：用kafka-logger插件收集API接口日志。

### 采纳理由
- 服务日志不再通过kafka，防止因kafka故障、网络抖动、服务器宕机等外部因素造成的信息丢失。
- 充分利用依赖自带的组件如zap，无需额外安装。
### 风险及应对措施
- 风险1: 全量采集导致fluent bit压力过大
- 应对措施: 按日志级别和比例采集日志。Debug采集1%，Info采集10%，Warn采集50%，Error和Fatal全量采集。

---

## ADR-009: Logstash更换为Fluent bit
### 日期
2025年12月17日
### 状态
已采纳
### 背景
- Logstash 8.18.8部署到K8S集群后空转状态下占用内存近800M，CPU使用1.52核，基础设施服务器仅4核8G，可能会出现Pod被K8S杀死的风险。
### 方案A
利用节点亲和性强制将Logstash调度到服务的运行环境里，减少基础设施服务器资源开销。
#### 优点
- 服务运行环境资源充足，可减少基础设施服务器的资源占用，腾出更多空间用于其他基础设施。
- 当前服务运行环境的节点资源占用远低于预期，部署Logstash影响较小。
#### 缺点
- Logstash极高的资源消耗仍未解决，存在资源争抢的问题。
### 方案B
用Fluent bit代替Logstash，采用DemonSet。
#### 优点
- 利用fluent bit多种输入来源的特性从K8S集群收集日志再写入ElasticSearch。
- Fluent bit在合理配置的前提下资源消耗较少，适用于资源紧张的环境。
#### 缺点
- 新组件需要花时间熟悉才能投入使用。
### 最终方案
采用方案B
### 采纳理由
- 虽然需要花时间熟悉Fluent bit但其带来的收益更高，显著解决资源开销过大的问题。
### 风险及应对措施
- 风险1: Filter不支持动态索引名称
- 应对措施: 通过LUA脚本实现

---

## ADR-008: 服务注册/发现及配置从Consul迁移至ETCD
### 日期
2025年12月09日
### 状态
已撤销
### 背景
目前基础设施服务器运行着数据库、ETCD和Consul，虽然服务器由2核4G升级到4核8G但仍面临资源紧张问题，后续要集成更多组件将继续拖慢系统响应速度，移除Consul可减少对系统资源和网络资源的占用。
### 最终方案
#### 
微服务：订单服务、商品服务的配置文件从Consul迁移到ETCD，引入go micro自带的ETCD组件完成服务注册和获取配置。

#### Apisix
服务发现（Discovery）由Consul改为ETCD。

### 采纳理由
- ETCD和Consul能完成服务注册/发现及配置存储，前三个版本保留Consul属于历史遗留问题。
- 移除Consul腾出更多资源应对其他组件，避免重复建设。

---

## ADR-007: 升级到事件驱动架构
### 日期
2025年11月28日
### 状态
已采纳
### 背景
DTM分布式事务直接调取数据库造成更严重的性能瓶颈，系统性能相比v1.0.1略有下降，而且耦合度开始上升。
### 方案A
利用Sarama组件和Kafka自研事件总线完成事件发布订阅，通过事件处理器实现handler接口的handle方法（类似Laravel的Job）完成事件订阅。
#### 优点
- 架构上达到自主可控，不受框架限制，后续迁移到其他框架无需做大幅度改动。
- 高度定制化broker组件满足后续更多自定义需求。
- 每个Job实现同样的接口方法便于统一处理，后续集成链路追踪较为方便。

#### 缺点
- 需自行实现消费者组，消费者的底层逻辑，难度极大。
- 设计初期要考虑到链路追踪、日志等需求，开发周期较长。

### 方案B
用broker结合kafka实现事件发布和订阅，对框架不支持的部分进行微调，基础设施层仅用于连接broker实现发布订阅，事件处理器放在接口层并利用框架自带的的语法糖注册订阅者，对框架不支持的部分微调底层源码。
#### 优点
- 无需自行事件总线，易于实现。

#### 缺点
- 依赖框架底层，其处理能力完全取决于框架本身的处理机制。

### 最终方案：方案B
### 采纳理由
- 虽然处理能力依赖框架底层，但自行开发事件总线代价太大存在诸多不确定因素，而框架自带的broker可以满足需求。

### 存在的风险及应对措施
#### 风险1
- 框架的处理机制对于不需要顺序消费的事件可能会限制其并行处理能力。
#### 应对措施1
- 持续监测，通过压测、观察kafka的消费情况检查消费能力瓶颈，若处理机制无法满足要求，考虑基于该broker进行深度改造替换原版broker以提升并行处理能力。

---

## ADR-006: 集成DTM分布式事务组件
### 日期
2025年11月18日
### 状态
已采纳
### 背景
系统需要使用分布式事务保证数据一致性，项目框架版本为2.9.1。

### 方案A
部署DTM到基础设施服务器，深度修改Go micro 2.9.1框架并集成低版本DTM，根据go-zero的原理移植驱动到go micro来集成。

#### 优点
- 任何层的代码都无需改动，减少集成带来的风险。

#### 缺点
- 虽然可以适当修改框架底层源码但风险较高，框架版本较旧具有许多不确定性。

### 方案B
- DTM部署在K8S集群，利用K8S自带的服务发现访问GRPC服务以解决服务调用，框架保持不变。

#### 优点
- 部署在K8S集群有效利用2台node子节点以缓解基础设施服务器资源紧张。
- 内置服务发现同样能调用GRPC服务。

#### 缺点
- 主要问题仍集中在框架，由于DTM组件较新，引入会修改或移除Go micro 2.9.1涉及的依赖，改造困难。

### 方案C
- 切换到go-zero或kratos确保无缝集成。

#### 优点
- go-zero和kratos有现成的组件可供使用，可以和DTM无缝衔接，虽然需要切换框架但更换后集成难度大幅下降。

#### 缺点
- 由于go micro是高度可插拔的框架，切换为go-zero或kratos耗时长
- 所有代码必须全部重写，代价较大。

### 最终方案
结合方案A和方案B的折中方案：
- 将DTM部署到K8S集群。
- 放弃go micro自带的GRPC客户端，用K8S内置的服务发现机制让DTM调用GRPC服务。
- 升级Go micro框架到v4.11.0版本。

### 采纳理由
- 利用K8S内置服务发现机制可保证DTM能访问到GRPC服务。
- DTM部署到K8S集群减缓基础设施服务器压力，让node节点的资源得以有效利用。
- 升级go micro到4.11.0版本防止DTM依赖影响框架底层，保证客户端顺利引入。
- 由于服务采用DDD领域驱动架构，修改范围仅限于main函数和基础设施层，其余无需改动，改动幅度小于A、B、C。
- 虽然切换到go-zero和kratos也可以但该服务2周迭代一版频率较高暂时不考虑。

### 关于方案C未被采纳的有关解释
- 目前可观测性仍存在缺陷，4.0版开始将完善基础设施，目前先保证可观测性和基本可用性。
- 3.0版将转向事件驱动架构，go-zero对于事件驱动的支持更加友好开发效率更高但该项目旨在熟悉kafka及事件驱动架构设计故暂时选用轻量级框架。
#### 迁移至go-zero时间点
- 在引入Jaeger、Prometheus、ELK之后。
- 压测后确定go micro v4存在严重性能瓶颈且严重影响到事件驱动。
- Go micro v4存在重大安全隐患。
- 优化难度显著高于切换至go-zero的代价。

---

## ADR-005: 分布式锁
### 日期
2025年11月13日
### 状态
已采纳
### 背景
订单支付回调API接口压测时存在并发请求问题需要阻止并发操作。
### 方案A
用Redis的SETNX实现分布式锁，将缓存限制在128M。
#### 优点
- Redis分布式锁讨论较多，又有现成的组件redlock，以往的项目经验大都使用Redis实现。
- Redis在内存操作性能高。
#### 缺点
- 当前基础设施服务器配置2核4GB内存，运行Consul、ETCD、MySQL等多个组件，再部署Redis性能将急剧下降。
### 方案B
用ETCD实现分布式锁，ETCD的租约、修订机制和K/V存储可以实现分布式锁。
#### 优点
- ETCD高可用，强一致性的特点结合锁自动续期即可实现，无需部署Redis。
- ETCD客户端v3版本支持分布式锁，已有golang组件且支持阻塞和非阻塞两种锁，可满足基本业务需求。
#### 缺点
- 服务器配置低可能对ETCD的稳定性造成负面影响。
### 最终方案
用ETCD实现分布式锁
### 采纳理由
当前服务器资源紧张无法再部署Redis，
### 风险及应对措施
- ETCD进行高频I/O操作内存上升极快，后续根据迭代的压测结果考虑迁移到K8S集群并调整优化参数，其余服务使用HPA。
- 将ETCD迁移到K8S后将服务注册/发现由Consul替换为ETCD进一步降低资源开销。

---

## ADR-004: Jenkins部署服务到K8S
### 日期
2025年10月27日
### 状态
已采纳
### 背景
Jenkins安装了2个K8S插件分别是Kubernetes和Kubernetes CLI，Kubernetes需要Pod模板较为复杂。
### 初步方案
使用Kubernetes插件在K8S集群上创建代理Pod部署，编写Pod模板。
#### 优点
- 直接使用插件集成到K8S完成部署。
#### 缺点
- 编写Pod模板较为复杂。
- 运行环境服务器CPU和内存资源已被划分，没有足够的空间运行Jenkins的代理Pod。
### 最终方案
放弃Kubernetes插件，改用Kubernetes CLI，结合kubeconfig和kubectl set image deployment实现部署，同时用rollout status监控部署状态，失败则回滚到最近一个reversion。
#### 采纳理由
- 直接使用kubectl命令，操作简单，不用在K8S集群运行代理类，节省服务器资源。

---

## ADR-003: 商品服务连接Consul加载K/V
### 日期
2025年10月23日

### 状态
已采纳

### 背景
商品服务的配置迁移到Consul的K/V后还要区分测试环境和生产环境，连接Consul成为启动项目最大的障碍。

### 初步方案
构建Docker镜像时复制config目录下的配置文件，在入口函数加载Consul配置。

#### 优点：
- 通过持久化的配置文件加载，减少代码层面的改动。

#### 缺点：
- 读取Consul配置后需要把K/V的信息解析到配置的结构体，即从多个源合并配置，合并操作需要手动实现。

### 最终方案
构建Docker镜像时结合构建参数将Consul基本配置注入到容器里的环境变量，通过环境变量获取Consul的地址和Token。

#### 采纳理由
- 构建镜像时通过参数通过注入到系统环境变量读取Consul连接信息连接获取K/V，彻底脱离配置文件。

#### 后果
- 构建镜像未携带参数或参数值错误将导致配置读取失败终止运行。
- 在部署阶段会出现数据暴露问题。

---

## ADR-002: 运行环境服务器配置 
### 日期
2025年10月22日
### 状态
已采纳
### 背景
Apisix、Apisix Ingress Controller及K8S底层组件、Docker需要消耗部分内存，2核 CPU和2GB内存可能不足以应对额外部署的两个服务。
### 考虑方案
### 方案A：细化服务器资源分配，降低2个服务的CPU和内存使用量。
#### 优点：
- 无需升级服务器，不会导致成本上升。
#### 缺点：
- Pod资源极度紧张，底层组件和服务可能崩溃。
- 压测时Golang服务无法发挥多核CPU的优势，代码层面优化空间极为有限，压测已无意义。
### 方案B：升级2台运行环境服务器配置为4核8GB
#### 优点：
- Pod资源明显增多，可以做压测，底层组件崩溃概率降低。
#### 缺点：
- 服务器耗费的成本上升。
### 决策结果
采用方案B：升级2台运行环境服务器配置为4核8GB
### 理由：
- 虽然成本上升，但可以保证服务器资源不紧张，为后续的压测做好准备。
- 留出足够的空间给Apisix和底层组件。
### 后果：
- 复杂调用链路仍可能出现资源紧张问题

---

## ADR-001: Apisix内置ETCD问题
### 日期
2025年10月22日
### 状态
已采纳
### 背景
用helm安装Apisix内置一个ETCD组件，该组件随Apisix一同部署到K8S集群，安装后ETCD一直卡在申请PVC，其他服务也无法启动。
### 考虑方案
### 方案A：使用NFS挂载，深入研究PV/PVC再做配置
#### 优点：
- 使用内置ETCD，无需编写Values配置文件。
#### 缺点：
- ETCD伴随Apisix部署在K8S集群增加了运行环境的压力，不符合生产环境要求。
- NFS挂载操作步骤较多。

### 方案B：使用外部ETCD
#### 优点：
- ETCD独立部署，无需考虑PV/PVC的问题。
#### 缺点：
- 基础设施服务器压力增加
### 决策结果
使用外部ETCD。
### 理由：
- 独立部署ETCD符合生产环境要求，后续若时间充足可考虑复用已有资源将服务注册/发现从Consul迁移到ETCD。
- 留出足够的空间给Apisix和底层组件。
### 实施方案：
1. 在基础设施服务器独立部署ETCD，Apisix的values.yaml文件配置关闭内置etcd连接外部ETCD，为网关、底层组件和2个服务腾出服务器资源。
2. 服务器仅2台且均为4核CPU和8GB内存，资源极为紧张，故需要对Apisix及其各项组件和服务进行精细化控制，资源分配如下：

| 组件                        | CPU requests | CPU limits | Memory requests | Memory limits | 副本数          |
|---------------------------|--------------|------------|-----------------|---------------|--------------|
| Apisix                    | 500m         | 1000m      | 512Mi           | 800Mi         | 2            |
| Apisix Gateway            | 500m         | 1000m      | 512Mi           | 1Gi           | 2            |
| Apisix Ingress Controller | 200m         | 500m       | 128Mi           | 256Mi         | 2            |
| 订单服务/商品服务                 | 500m         | 1000m      | 256Mi           | 512Mi         | 2（每个服务各2个副本） | 

累计共分配3.5核 CPU和约3.03G内存，可供底层组件稳定运行，各组件可正常运行，防止单节点资源耗尽。

### 后果：
- 基础设施服务器压力增加，目前基础设施服务器安装了Jenkins、MySQL、Harbor、Redis、Docker、Consul但配置仅为2核 CPU和4GB内存。
- 压测过程中可能需要暂时关闭jenkins。
- 单节点ETCD发生故障会造成Apisix崩溃。